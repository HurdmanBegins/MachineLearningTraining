{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Data Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectif : trier des données textuelles par type.  \n",
    "Les types possibles sont :  \n",
    "2 : code postal  \n",
    "3 : coordonnées GPS  \n",
    "4 : adresse  \n",
    "5 : numéro SIRET  \n",
    "6 : Année  \n",
    "7 : Date  \n",
    "8 : SIREN  \n",
    "9 : Code NAF/APE  \n",
    "10 : Autre  \n",
    "11 : Téléphone  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour manipuler et analyser des données sous formes de tableaux, on utilise pandas\n",
    "import pandas as pd\n",
    "# Pour importer les fichiers CSV, on utilise glob\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13194 entries, 0 to 13193\n",
      "Data columns (total 29 columns):\n",
      "Dispositif                                                                   13194 non-null object\n",
      "Type de structure                                                            13194 non-null object\n",
      "Année d'agrément                                                             13194 non-null object\n",
      "Localisation                                                                 10167 non-null object\n",
      "Début d'agrément                                                             13194 non-null int64\n",
      "Fin d'agrément                                                               13194 non-null int64\n",
      "Numéro SIREN                                                                 10107 non-null float64\n",
      "Nom de l'entreprise                                                          13194 non-null object\n",
      "Sigle                                                                        4021 non-null object\n",
      "Activité                                                                     12947 non-null object\n",
      "Code postal                                                                  13042 non-null object\n",
      "Ville                                                                        13193 non-null object\n",
      "Téléphone                                                                    0 non-null float64\n",
      "Base SIRENE : Catégorie de l'établissement siège                             9268 non-null object\n",
      "Lien vers la fiche scanR                                                     8170 non-null object\n",
      "Commune                                                                      10167 non-null object\n",
      "Unité urbaine                                                                10167 non-null object\n",
      "Département                                                                  10167 non-null object\n",
      "Académie                                                                     10167 non-null object\n",
      "Région                                                                       10167 non-null object\n",
      "Géolocalisation                                                              13194 non-null object\n",
      "Code commune (France)                                                        10167 non-null object\n",
      "Code de l'unité urbaine (France)                                             10167 non-null object\n",
      "Code du département (France)                                                 10167 non-null object\n",
      "Base SIRENE : Activité principale exercée (APE) par l'établissement siège    9415 non-null object\n",
      "Code de l'académie (France)                                                  10167 non-null object\n",
      "Code de la région (France)                                                   10167 non-null object\n",
      "Pays                                                                         13194 non-null object\n",
      "Base SIRENE : Code APE de l'établissement siège                              9415 non-null object\n",
      "dtypes: float64(2), int64(2), object(25)\n",
      "memory usage: 2.9+ MB\n",
      "---------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2492 entries, 0 to 2491\n",
      "Data columns (total 11 columns):\n",
      "ID                                                    2492 non-null object\n",
      "Date                                                  2492 non-null object\n",
      "Axe                                                   2492 non-null object\n",
      "Départ                                                2492 non-null object\n",
      "Arrivée                                               2492 non-null object\n",
      "Nombre de trains programmés                           2484 non-null float64\n",
      "Nombre de trains ayant circulé                        2483 non-null float64\n",
      "Nombre de trains annulés                              2487 non-null float64\n",
      "Nombre de trains en retard à l'arrivée                2487 non-null float64\n",
      "Taux de régularité                                    2475 non-null float64\n",
      "Nombre de trains à l'heure pour un train en retard    2408 non-null float64\n",
      "dtypes: float64(6), object(5)\n",
      "memory usage: 214.2+ KB\n",
      "---------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12811 entries, 0 to 12810\n",
      "Columns: 118 entries, SIREN to TEL\n",
      "dtypes: float64(43), int64(14), object(61)\n",
      "memory usage: 11.5+ MB\n",
      "---------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 207895 entries, 0 to 207894\n",
      "Data columns (total 8 columns):\n",
      "Type d'axe           207895 non-null object\n",
      "Axe                  207895 non-null object\n",
      "latitude (WGS84)     207895 non-null float64\n",
      "longitude (WGS84)    207895 non-null float64\n",
      "Opérateur            202272 non-null object\n",
      "Technologie          207895 non-null object\n",
      "Chargement < 10s     207895 non-null float64\n",
      "coord                207895 non-null object\n",
      "dtypes: float64(3), object(5)\n",
      "memory usage: 12.7+ MB\n",
      "---------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24923 entries, 0 to 24922\n",
      "Data columns (total 8 columns):\n",
      "JOUR               24923 non-null object\n",
      "CODE_STIF_TRNS     24923 non-null int64\n",
      "CODE_STIF_RES      24923 non-null int64\n",
      "CODE_STIF_LIGNE    24923 non-null int64\n",
      "LIBELLE_LIGNE      24923 non-null object\n",
      "ID_GROUPOFLINES    24923 non-null object\n",
      "CATEGORIE_TITRE    24923 non-null object\n",
      "NB_VALD            24923 non-null object\n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 1.5+ MB\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "# On récupère tous les CSV situés dans le répertoire \"./data\" du Jupyter notebook\n",
    "files = glob.glob(\"./data/*.csv\")\n",
    "\n",
    "# On visualise les colonnes du jeu de données pour voir un peu la tête que ça a pour chaque CSV\n",
    "for file in files:\n",
    "    df = pd.read_csv(file, sep=\";\")\n",
    "    df.info()\n",
    "    # Ajout d'un séparateur pour mieux séparer les changements de CSV visuellement\n",
    "    print(\"---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Axe</th>\n",
       "      <th>Départ</th>\n",
       "      <th>Arrivée</th>\n",
       "      <th>Nombre de trains programmés</th>\n",
       "      <th>Nombre de trains ayant circulé</th>\n",
       "      <th>Nombre de trains annulés</th>\n",
       "      <th>Nombre de trains en retard à l'arrivée</th>\n",
       "      <th>Taux de régularité</th>\n",
       "      <th>Nombre de trains à l'heure pour un train en retard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2420</th>\n",
       "      <td>INT_16_A</td>\n",
       "      <td>2017-12</td>\n",
       "      <td>Atlantique Méd.</td>\n",
       "      <td>HENDAYE</td>\n",
       "      <td>TOULOUSE MATABIAU</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>88.6</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2315</th>\n",
       "      <td>INT_22_A</td>\n",
       "      <td>2017-05</td>\n",
       "      <td>Centre Sud-Ouest</td>\n",
       "      <td>PARIS AUSTERLITZ</td>\n",
       "      <td>TOURS</td>\n",
       "      <td>109.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>76.1</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>INT_14_A</td>\n",
       "      <td>2014-05</td>\n",
       "      <td>Est Centre</td>\n",
       "      <td>CLERMONT FERRAND</td>\n",
       "      <td>PARIS BERCY</td>\n",
       "      <td>285.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>96.5</td>\n",
       "      <td>27.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>INT_7_B</td>\n",
       "      <td>2018-01</td>\n",
       "      <td>Nord</td>\n",
       "      <td>PARIS-NORD</td>\n",
       "      <td>BOULOGNE-VILLE</td>\n",
       "      <td>152.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>85.7</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>INT_7_B</td>\n",
       "      <td>2016-06</td>\n",
       "      <td>Nord-Normandie</td>\n",
       "      <td>PARIS NORD</td>\n",
       "      <td>BOULOGNE</td>\n",
       "      <td>73.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>91.8</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID     Date               Axe            Départ  \\\n",
       "2420  INT_16_A  2017-12   Atlantique Méd.           HENDAYE   \n",
       "2315  INT_22_A  2017-05  Centre Sud-Ouest  PARIS AUSTERLITZ   \n",
       "805   INT_14_A  2014-05        Est Centre  CLERMONT FERRAND   \n",
       "2128   INT_7_B  2018-01              Nord        PARIS-NORD   \n",
       "1850   INT_7_B  2016-06    Nord-Normandie        PARIS NORD   \n",
       "\n",
       "                Arrivée  Nombre de trains programmés  \\\n",
       "2420  TOULOUSE MATABIAU                         35.0   \n",
       "2315              TOURS                        109.0   \n",
       "805         PARIS BERCY                        285.0   \n",
       "2128     BOULOGNE-VILLE                        152.0   \n",
       "1850           BOULOGNE                         73.0   \n",
       "\n",
       "      Nombre de trains ayant circulé  Nombre de trains annulés  \\\n",
       "2420                            35.0                       0.0   \n",
       "2315                           109.0                       0.0   \n",
       "805                            284.0                       1.0   \n",
       "2128                           147.0                       5.0   \n",
       "1850                            73.0                       0.0   \n",
       "\n",
       "      Nombre de trains en retard à l'arrivée  Taux de régularité  \\\n",
       "2420                                     4.0                88.6   \n",
       "2315                                    26.0                76.1   \n",
       "805                                     10.0                96.5   \n",
       "2128                                    21.0                85.7   \n",
       "1850                                     6.0                91.8   \n",
       "\n",
       "      Nombre de trains à l'heure pour un train en retard  \n",
       "2420                                                7.8   \n",
       "2315                                                3.2   \n",
       "805                                                27.4   \n",
       "2128                                                6.0   \n",
       "1850                                               11.2   "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ici, je vérifie manuellement de quel type semble être la donnée (exemple ici pour le CSV 2)\n",
    "df = pd.read_csv(files[1], sep=\";\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cet exemple, je ne suis intéressé que par la colonne date globalement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée un pseudo-switch qui permet de connaître le type de la donnée en fonction du nom de la colonne du CSV\n",
    "# Je procède via un grand nombre de \"elif\" car il n'y a pas de switch/case en Python\n",
    "# Et que je galère pas mal avec les dictionnaires par manque d'habitude\n",
    "def returnType(colName):\n",
    "    # Code postaux\n",
    "    if colName in [\"Code commune (France)\"]:\n",
    "        return 2\n",
    "    # Coordonnées GPS\n",
    "    elif colName in [\"Géolocalisation\", \"coord\"]:\n",
    "        return 3\n",
    "    # Adresses\n",
    "    elif colName in [\"L4_NORMALISEE\", \"L6_NORMALISEE\"]:\n",
    "        return 4\n",
    "    # Numéros SIRET\n",
    "    elif colName in [\"SIRETPS\"]:\n",
    "        return 5\n",
    "    # Années\n",
    "    elif colName in [\"Début d'agrément\", \"Fin d'agrément\"]:\n",
    "        return 6\n",
    "    # Dates\n",
    "    elif colName in [\"Date\", \"JOUR\"]:\n",
    "        return 7\n",
    "    # Numéros SIREN\n",
    "    elif colName in [\"Numéro SIREN\", \"SIREN\"]:\n",
    "        return 8\n",
    "    # Codes NAF/APE\n",
    "    elif colName in [\"Base SIRENE : Code APE de l'établissement siège\"]:\n",
    "        return 9\n",
    "    # Téléphones\n",
    "    elif colName in [\"TEL\", \"Téléphone\"]:\n",
    "        return 11\n",
    "    # Defaut\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterating on file ./data\\fr-esr-cir-et-cii-organismes-et-bureaux-de-style-agrees.csv\n",
      "processing column Début d'agrément\n",
      "processing column Fin d'agrément\n",
      "processing column Numéro SIREN\n",
      "processing column Téléphone\n",
      "processing column Géolocalisation\n",
      "processing column Code commune (France)\n",
      "processing column Base SIRENE : Code APE de l'établissement siège\n",
      "iterating on file ./data\\regularite-mensuelle-intercites.csv\n",
      "processing column Date\n",
      "iterating on file ./data\\sirc-17804_9075_61171_2018102_E_Q_20180413_015943916.csv\n",
      "processing column SIREN\n",
      "processing column L4_NORMALISEE\n",
      "processing column L6_NORMALISEE\n",
      "processing column SIRETPS\n",
      "processing column TEL\n",
      "iterating on file ./data\\telecom_qualite_services_mobiles_07-2016.csv\n",
      "processing column coord\n",
      "iterating on file ./data\\validations-sur-le-reseau-de-surface-nombre-de-validations-par-jour-1er-semestr0.csv\n",
      "processing column JOUR\n"
     ]
    }
   ],
   "source": [
    "# On crée une liste temporaire destinée à recevoir les contenus\n",
    "tempList = []\n",
    "\n",
    "# Pour chaque CSV, on crée une DataFrame\n",
    "for file in files:\n",
    "    print(\"iterating on file \" + file)\n",
    "    df = pd.read_csv(file, sep=\";\")\n",
    "    # Pour chaque colonne du DataFrame actuellement parcouru\n",
    "    for col in df.columns:\n",
    "        # On check si la colonne renvoi un type attendu (ou 0 par défaut)\n",
    "        if returnType(col) != 0:\n",
    "            print(\"processing column \" + col)\n",
    "            # Si le type est attendu, on va récupérer tout le contenu de la colonne ainsi que l'indice de type correspondant\n",
    "            indice = returnType(col)\n",
    "            valeurs = df[col].tolist()\n",
    "            # Pour chaque valeur, on va imprimer dans la liste temporaire [indice, valeur]\n",
    "            for valeur in valeurs:\n",
    "                tempList.append([indice, str(valeur)])\n",
    "\n",
    "# Lorsque tous les CSV sont traités, on transforme la liste temporaire en DataFrame\n",
    "dfsum = pd.DataFrame(tempList, columns=[\"y\", \"X\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22954</th>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258102</th>\n",
       "      <td>3</td>\n",
       "      <td>43.20906, 5.6278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253646</th>\n",
       "      <td>3</td>\n",
       "      <td>48.80823, 2.99401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354630</th>\n",
       "      <td>3</td>\n",
       "      <td>48.085, 3.5147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179888</th>\n",
       "      <td>3</td>\n",
       "      <td>42.13431, 9.14056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287624</th>\n",
       "      <td>3</td>\n",
       "      <td>50.713695, 2.69201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332236</th>\n",
       "      <td>3</td>\n",
       "      <td>43.84776, 4.39081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285775</th>\n",
       "      <td>3</td>\n",
       "      <td>48.36411, 1.70077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192291</th>\n",
       "      <td>3</td>\n",
       "      <td>48.30729, 1.86196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273197</th>\n",
       "      <td>3</td>\n",
       "      <td>50.16453, 1.72202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182702</th>\n",
       "      <td>3</td>\n",
       "      <td>48.97249, 2.04483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270302</th>\n",
       "      <td>3</td>\n",
       "      <td>42.21816, 9.17492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53858</th>\n",
       "      <td>3</td>\n",
       "      <td>50.503887, 4.469936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34658</th>\n",
       "      <td>8</td>\n",
       "      <td>523404226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264899</th>\n",
       "      <td>3</td>\n",
       "      <td>48.11215, -1.11656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        y                    X\n",
       "22954   6                 2016\n",
       "258102  3     43.20906, 5.6278\n",
       "253646  3    48.80823, 2.99401\n",
       "354630  3       48.085, 3.5147\n",
       "179888  3    42.13431, 9.14056\n",
       "287624  3   50.713695, 2.69201\n",
       "332236  3    43.84776, 4.39081\n",
       "285775  3    48.36411, 1.70077\n",
       "192291  3    48.30729, 1.86196\n",
       "273197  3    50.16453, 1.72202\n",
       "182702  3    48.97249, 2.04483\n",
       "270302  3    42.21816, 9.17492\n",
       "53858   3  50.503887, 4.469936\n",
       "34658   8          523404226.0\n",
       "264899  3   48.11215, -1.11656"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On affiche le contenu d'une 15aine de lignes, on doit voir un peu de tout (dates, coordonnées GPS, adresses, etc)\n",
    "dfsum.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de maintenant, je vais utiliser ce dfsum (le DataFrame qui contient la somme traitée de mes CSV) pour entrainer mon machine learning.\n",
    "Pour des raisons de simplicité je renomme mon dfsum en df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C'est parti pour le machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe une fonction qui convertit des contenus de documents texte en une matrice de comptage de mots/caractères\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On détermine qu'un token (fragment de mot) fais la taille d'un mot (à partir de 2 caractères)\n",
    "vectorizer = CountVectorizer(\n",
    "    input=\"content\",\n",
    "    analyzer=\"char\",\n",
    "    strip_accents=None,\n",
    "    stop_words=None,\n",
    "    binary=True,\n",
    "    ngram_range=(1,2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On tokenize (on \"distingue\" les mots/caractères de la donnée)\n",
    "tokenizer = vectorizer.build_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On analyse (on distingue des suites de n mots/caractères)\n",
    "analyzer = vectorizer.build_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe une fonction qui segmente les données en jeux d'entrainement et de tests)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xepyon\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X = df['X']\n",
    "y = df['y']\n",
    "\n",
    "# A l'aide de train_test_split, on va éclater le jeu de données en données d'entrainement (70%) et de test (le reste)\n",
    "# Pour éviter un avertissement récurrent \"FutureWarning\", je fixe le jeu de test à 0.3 (le reste)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    train_size = 0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y     X\n",
       "0  6  2012\n",
       "1  6  2012\n",
       "2  6  2012\n",
       "3  6  2012\n",
       "4  6  2012"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On jette un oeil au format des données d'entrainement de X\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe une fonction qui applique des transformations aux données afin d'obtenir une évaluation finale\n",
    "from sklearn.pipeline import Pipeline\n",
    "# On importe un classifieur pour les modèles Multinomiaux\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée un pipeline de traitement, puis on vectorise les données textuelles et enfin on les classifie\n",
    "classifier = MultinomialNB()\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vectorizer\", vectorizer),\n",
    "        (\"classifier\", classifier)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit done\n"
     ]
    }
   ],
   "source": [
    "# On entraine le classifier sur les données d'entrainement\n",
    "pipeline.fit(X_train.values, Y_train.values)\n",
    "# Comme ça peut prendre un petit moment, on imprime un \"fit done\" à la fin pour avertir de l'arrêt du traitement\n",
    "print(\"fit done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On utilise le pipeline entrainé sur les données de test\n",
    "Y_predicted = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  8,  6,  3,  3,  3,  2,  3, 11], dtype=int64)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On regarde les résultats des 10 premières lignes\n",
    "Y_predicted[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score f1 0.9200030633865738\n"
     ]
    }
   ],
   "source": [
    "# On importe une fonction qui calcule le f1_score (le rapport entre la précision et le rappel)\n",
    "from sklearn.metrics import f1_score\n",
    "# On calcule le f1_score pour toutes les prédictions effectuées\n",
    "score = f1_score(\n",
    "    Y_test,\n",
    "    Y_predicted,\n",
    "    average=\"micro\"\n",
    ")\n",
    "print(\"score f1\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le score f1 du jeu d'entraînement est de 0.92 soit 92% de réussite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score f1 0.921748612357133\n"
     ]
    }
   ],
   "source": [
    "# Maintenant on va tester la même chose sur les données qui sont réellement à évaluer (les données de test)\n",
    "Y_predicted_train = pipeline.predict(X_train)\n",
    "# Calcul du score f1\n",
    "score = f1_score(\n",
    "    Y_train,\n",
    "    Y_predicted_train,\n",
    "    average=\"micro\"\n",
    ")\n",
    "print(\"score f1\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le score f1 du jeu de test est de 0.9217 soit 92.17% de réussite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert data to test : 49100\n",
      "Data type is : code postal\n"
     ]
    }
   ],
   "source": [
    "# Pour s'amuser un peu (et pour voir si les données soumises sont correctement évaluées accessoirement)\n",
    "# on va permettre de tester directement dans le notebook via un input\n",
    "dataToTest = input(\"Insert data to test : \")\n",
    "# On \"cast\" les data à tester en Array via [] car predict attend un iterable\n",
    "dataType = pipeline.predict([dataToTest])\n",
    "# On crée un dictionnaire de données pour avoir la correspondance indice/type de donnée\n",
    "typeDict = {\n",
    "    2 : \"code postal\",\n",
    "    3 : \"coordonnées GPS\",\n",
    "    4 : \"adresse\",\n",
    "    5 : \"numéro SIRET\",\n",
    "    6 : \"Année\",\n",
    "    7 : \"Date\",\n",
    "    8 : \"SIREN\",\n",
    "    9 : \"Code NAF/APE\",\n",
    "    11 : \"Téléphone\"\n",
    "}\n",
    "print(\"Data type is : \" + typeDict.get(int(dataType)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe la matrice de confusion (vrai positifs/vrai négatifs/faux positifs/faux négatifs)\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1507   332     0     0    64     1  1083    50   945]\n",
      " [    0 66451     0     0     0     0     0     0     0]\n",
      " [    0     0  7585     0     0     0     0     1    35]\n",
      " [    0     0     0     0     0     0   334     0  3600]\n",
      " [    0     0     0     0  7869    21     0     0     0]\n",
      " [    0     0     0     0     0  8218     0     0     0]\n",
      " [  456    28     0     0     0     0  6375     0   937]\n",
      " [   47     0     0     0     0     0     1  2729  1113]\n",
      " [    0     3     0     0     0     0   350     0  7382]]\n"
     ]
    }
   ],
   "source": [
    "# La matrice de confusion est très utile car elle permet de voir les vrais/faux positifs/négatifs\n",
    "print(confusion_matrix(Y_test.values, Y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
